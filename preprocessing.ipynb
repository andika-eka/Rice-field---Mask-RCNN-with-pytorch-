{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"Original\"\n",
    "lable_dir = \"Mask\"\n",
    "dataset = [{\"image\":image_dir + '/' + imgPath, \"label\":lable_dir+ '/' + label_path} for imgPath, label_path in zip(os.listdir(image_dir), os.listdir(lable_dir))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "dataset_shuffle = dataset.copy()\n",
    "random.shuffle(dataset_shuffle)\n",
    "\n",
    "train_split = int(len(dataset_shuffle) * train_ratio)\n",
    "val_split = int(len(dataset_shuffle) * val_ratio)\n",
    "\n",
    "data_train = dataset_shuffle[:train_split]\n",
    "data_validation = dataset_shuffle[train_split:train_split+val_split]\n",
    "data_test = dataset_shuffle[train_split+val_split:]\n",
    "\n",
    "json.dump(data_train, open('data_train.json', 'w'), indent=4)\n",
    "json.dump(data_validation, open('data_validation.json', 'w'), indent=4)\n",
    "json.dump(data_test, open('data_test.json', 'w'), indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = json.loads(open('data_train.json').read())\n",
    "data_validation = json.loads(open('data_validation.json').read())\n",
    "data_test = json.loads(open('data_test.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def crop_data(image, mask, dimension):\n",
    "    \n",
    "    x, y, w, h = dimension\n",
    "    \n",
    "    image = image[y:y+h, x:x+w]\n",
    "    mask = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def resize_data(image, mask, size):\n",
    "    \n",
    "    image = cv2.resize(image, size)\n",
    "    mask = cv2.resize(mask, size)\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "def augment_data(image, mask):\n",
    "    \n",
    "    flip_image = [image]\n",
    "    flip_mask  = [mask]\n",
    "    \n",
    "    tmp_image = cv2.flip(image, 1)\n",
    "    tmp_mask = cv2.flip(mask, 1)\n",
    "    \n",
    "    flip_image.append(tmp_image)\n",
    "    flip_mask.append(tmp_mask)\n",
    "    \n",
    "    tmp_image = cv2.flip(image, 0)\n",
    "    tmp_mask = cv2.flip(mask, 0)\n",
    "    \n",
    "    flip_image.append(tmp_image)\n",
    "    flip_mask.append(tmp_mask)\n",
    "    \n",
    "    augmented_image = flip_image.copy()\n",
    "    augmented_mask = flip_mask.copy()\n",
    "    rotate_code = [cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n",
    "    \n",
    "    for i in range(3):\n",
    "        for image, mask in zip(flip_image, flip_mask):\n",
    "            tmp_image = cv2.rotate(image, rotate_code[i])\n",
    "            tmp_mask = cv2.rotate(mask, rotate_code[i])\n",
    "            \n",
    "            augmented_image.append(tmp_image)\n",
    "            augmented_mask.append(tmp_mask)\n",
    "    \n",
    "    return augmented_image, augmented_mask\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "image_path_out = \"image_crop_512\"\n",
    "mask_path_out = \"mask_crop_512\"\n",
    "\n",
    "if os.path.exists(image_path_out):\n",
    "    shutil.rmtree(image_path_out)\n",
    "if os.path.exists(mask_path_out):\n",
    "    shutil.rmtree(mask_path_out)\n",
    "os.mkdir(image_path_out)\n",
    "os.mkdir(mask_path_out)\n",
    "data_count = 0\n",
    "for data in data_train:\n",
    "    image = cv2.imread(data[\"image\"])\n",
    "    mask = cv2.imread(data[\"label\"])\n",
    "    \n",
    "    image_crop, mask_crop = crop_data(image, mask, (500, 0 , 1080, 1080))\n",
    "    image_resize, mask_resize = resize_data(image_crop, mask_crop, (512, 512))\n",
    "    \n",
    "    image_augmented, mask_augmented = augment_data(image_resize, mask_resize)\n",
    "    \n",
    "    for new_image, new_mask in zip(image_augmented, mask_augmented):\n",
    "        cv2.imwrite(image_path_out + \"/\" + str(data_count) + \".png\", new_image)\n",
    "        cv2.imwrite(mask_path_out + \"/\" + str(data_count) + \".png\", new_mask)\n",
    "        data_count += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "json_path = \"json_crop_512\"\n",
    "out_image_path = \"out_image\"\n",
    "\n",
    "if os.path.exists(json_path):\n",
    "    shutil.rmtree(json_path)\n",
    "if os.path.exists(out_image_path):\n",
    "    shutil.rmtree(out_image_path)\n",
    "os.mkdir(json_path)\n",
    "os.mkdir(out_image_path)\n",
    "\n",
    "image_train_dir = \"image_crop_512\"\n",
    "mask_train_dir = \"mask_crop_512\"\n",
    "for mask_path, image_path in zip(os.listdir(mask_train_dir), os.listdir(image_train_dir)):\n",
    "    mask = cv2 .imread(os.path.join(mask_train_dir, mask_path))\n",
    "    image = cv2.imread(os.path.join(image_train_dir, image_path))    \n",
    "    copy_image = image.copy()\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "    gray = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)[1]\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    boxes = torch.zeros([len(contours),4], dtype=torch.float32)\n",
    "\n",
    "    data = {\n",
    "        \"file\" : image_path,\n",
    "        \"n_object\": len(contours),\n",
    "        \"annotation\" : [],\n",
    "        \"box\" : []\n",
    "    }    \n",
    "    \n",
    "    for i,contour in enumerate(contours) :\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        boxes[i] = torch.tensor([x,y, x+w, y+h])\n",
    "        boxed_image = cv2.rectangle(copy_image, (x,y), (x+w, y+h), (0,255,255), 2)\n",
    "        data[\"annotation\"].append(contour.tolist())\n",
    "        data[\"box\"].append([x,y,x+w, y+h])\n",
    "    with open(os.path.join(json_path,image_path.replace(\".png\", \".json\")), \"w\") as file:\n",
    "        json.dump(data,file)\n",
    "        \n",
    "\n",
    "    cv2.drawContours(image, contours, -1, (0, 255, 0), 3)\n",
    "    cv2.fillPoly(image, contours, (0, 255, 0, 100))\n",
    "    image = cv2.addWeighted(image, 0.5, copy_image, 0.5, 0)\n",
    "    cv2.imwrite(os.path.join(out_image_path,image_path), image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_preset = [\n",
    "    {\n",
    "        \"name\" : \"crop_512\",\n",
    "        \"size\" : (512, 512),\n",
    "        \"method\" : \"crop\"\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"resize_512\",\n",
    "        \"size\" : (512, 512),\n",
    "        \"method\" : \"resize\"\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"crop_128\",\n",
    "        \"size\" : (128, 128),\n",
    "        \"method\" : \"crop\"\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"resize_128\",\n",
    "        \"size\" : (128, 128),\n",
    "        \"method\" : \"resize\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "def preprocessing(out_path, data_path, output_size, method, crop_coordiate = None, test = False):\n",
    "    \n",
    "    image_path_out = os.path.join(out_path,\"image\")\n",
    "    mask_path_out = os.path.join(out_path,\"mask\")\n",
    "    result_path_out = os.path.join(out_path, \"result\")\n",
    "\n",
    "    if os.path.exists(image_path_out):\n",
    "        shutil.rmtree(image_path_out)\n",
    "    if os.path.exists(mask_path_out):\n",
    "        shutil.rmtree(mask_path_out)\n",
    "    if os.path.exists(result_path_out):\n",
    "        shutil.rmtree(result_path_out)\n",
    "    os.mkdir(result_path_out)\n",
    "    os.mkdir(image_path_out)\n",
    "    os.mkdir(mask_path_out)\n",
    "    data_count = 0\n",
    "    for data in data_path:\n",
    "        image = cv2.imread(data[\"image\"])\n",
    "        mask = cv2.imread(data[\"label\"])\n",
    "        \n",
    "        if method == \"crop\":\n",
    "            image_crop, mask_crop = crop_data(image, mask, crop_coordiate)\n",
    "            image_resize, mask_resize = resize_data(image_crop, mask_crop, output_size)\n",
    "        elif method == \"resize\":\n",
    "            image_resize, mask_resize = resize_data(image, mask, output_size)\n",
    "            \n",
    "        if test :\n",
    "            cv2.imwrite(image_path_out + \"/\" + str(data_count) + \".png\", image_resize)\n",
    "            cv2.imwrite(mask_path_out + \"/\" + str(data_count) + \".png\", mask_resize)\n",
    "            data_count += 1\n",
    "        else:\n",
    "            image_augmented, mask_augmented = augment_data(image_resize, mask_resize)\n",
    "            for new_image, new_mask in zip(image_augmented, mask_augmented):\n",
    "                cv2.imwrite(image_path_out + \"/\" + str(data_count) + \".png\", new_image)\n",
    "                cv2.imwrite(mask_path_out + \"/\" + str(data_count) + \".png\", new_mask)\n",
    "                data_count += 1\n",
    "\n",
    "def convert2annotation(path, visualize=False):\n",
    "    json_path = os.path.join(path, \"json\")\n",
    "    out_image_path = os.path.join(path, \"annotated\")\n",
    "\n",
    "    if os.path.exists(json_path):\n",
    "        shutil.rmtree(json_path)\n",
    "    if os.path.exists(out_image_path):\n",
    "        shutil.rmtree(out_image_path)\n",
    "    os.mkdir(json_path)\n",
    "    os.mkdir(out_image_path)\n",
    "\n",
    "    image_train_dir = os.path.join(path, \"image\")\n",
    "    mask_train_dir = os.path.join(path, \"mask\")\n",
    "    for mask_path, image_path in zip(os.listdir(mask_train_dir), os.listdir(image_train_dir)):\n",
    "        mask = cv2 .imread(os.path.join(mask_train_dir, mask_path))\n",
    "        image = cv2.imread(os.path.join(image_train_dir, image_path))    \n",
    "        copy_image = image.copy()\n",
    "        mask = cv2.bitwise_not(mask)\n",
    "        gray = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)[1]\n",
    "        contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "        boxes = torch.zeros([len(contours),4], dtype=torch.float32)\n",
    "\n",
    "        data = {\n",
    "            \"file\" : image_path,\n",
    "            \"n_object\": len(contours),\n",
    "            \"annotation\" : [],\n",
    "            \"box\" : []\n",
    "        }    \n",
    "        \n",
    "        for i,contour in enumerate(contours) :\n",
    "            x,y,w,h = cv2.boundingRect(contour)\n",
    "            boxes[i] = torch.tensor([x,y, x+w, y+h])\n",
    "            boxed_image = cv2.rectangle(copy_image, (x,y), (x+w, y+h), (0,255,255), 2)\n",
    "            data[\"annotation\"].append(contour.tolist())\n",
    "            data[\"box\"].append([x,y,x+w, y+h])\n",
    "        with open(os.path.join(json_path,image_path.replace(\".png\", \".json\")), \"w\") as file:\n",
    "            json.dump(data,file)\n",
    "            \n",
    "        if visualize:\n",
    "            cv2.drawContours(boxed_image, contours, -1, (0, 255, 0), 1)\n",
    "            cv2.fillPoly(image, contours, (0, 255, 0, 100))\n",
    "            image = cv2.addWeighted(image, 0.5, copy_image, 0.5, 0)\n",
    "            cv2.imwrite(os.path.join(out_image_path,image_path), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in preprocessing_preset:\n",
    "    if os.path.exists(experiment[\"name\"]):\n",
    "        shutil.rmtree(experiment[\"name\"])\n",
    "\n",
    "    os.mkdir(experiment[\"name\"])\n",
    "    \n",
    "    preprocessing(experiment[\"name\"], data_train, experiment[\"size\"], experiment[\"method\"], (500, 0 , 1080, 1080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in preprocessing_preset:\n",
    "    if os.path.exists(experiment[\"name\"]+\"/test\"):\n",
    "        shutil.rmtree(experiment[\"name\"]+\"/test\")\n",
    "\n",
    "    os.mkdir(experiment[\"name\"]+\"/test\")\n",
    "    preprocessing(experiment[\"name\"]+\"/test\", data_test, experiment[\"size\"], experiment[\"method\"],crop_coordiate = (500, 0 , 1080, 1080), test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_preset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_920\\4264708986.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreprocessing_preset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mconvert2annotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocessing_preset' is not defined"
     ]
    }
   ],
   "source": [
    "for experiment in preprocessing_preset:\n",
    "    convert2annotation(experiment[\"name\"], visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_object': 3, 'box': [[0, 303, 151, 512], [217, 0, 512, 512], [0, 0, 65, 102]]}\n"
     ]
    }
   ],
   "source": [
    "mask = cv2 .imread(\"./resize_512/mask/1441.png\")\n",
    "image = cv2.imread(\"./resize_512/image/1441.png\")\n",
    "    \n",
    "copy_image = image.copy()\n",
    "mask = cv2.bitwise_not(mask)\n",
    "gray = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY)[1]\n",
    "contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "boxes = torch.zeros([len(contours),4], dtype=torch.float32)\n",
    "\n",
    "data = {\n",
    "    # \"file\" : image_path,\n",
    "    \"n_object\": len(contours),\n",
    "    # \"annotation\" : [],\n",
    "    \"box\" : []\n",
    "}    \n",
    "\n",
    "for i,contour in enumerate(contours) :\n",
    "    # contour = contour.reshape(-1, 1, 2)\n",
    "    x,y,w,h = cv2.boundingRect(contour)\n",
    "    boxes[i] = torch.tensor([x,y, x+w, y+h])\n",
    "    boxed_image = cv2.rectangle(copy_image, (x,y), (x+w, y+h), (255,255, 1), 2)\n",
    "    # data[\"annotation\"].append(contour.tolist())\n",
    "    data[\"box\"].append([x,y,x+w, y+h])\n",
    "    contour = np.array([i[0] for i in contour])\n",
    "    # print(contour)\n",
    "    cv2.drawContours(boxed_image, [contour], -1, (random.randint(0,255), random.randint(0, 255), random.randint(0, 255)), 1)\n",
    "    cv2.fillPoly(boxed_image, [contour], (random.randint(0,255), random.randint(0, 255), random.randint(0, 255)))\n",
    "# with open(os.path.join(json_path,image_path.replace(\".png\", \".json\")), \"w\") as file:\n",
    "#     json.dump(data,file)\n",
    "    \n",
    "print(data)\n",
    "disp = np.concatenate((image, mask,boxed_image), axis=1)\n",
    "cv2.imshow(\"disp\", disp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# image = cv2.addWeighted(image, 0.5, copy_image, 0.5, 0)\n",
    "# cv2.imwrite(os.path.join(out_image_path,image_path), image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4525b0e4e49659477bff12adecf1530247869591c722f642676ae21d2312cce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
